{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.sparse.linalg import svds\n",
    "from typing import Optional, Union\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from polara.tools.display import print_frames\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "\n",
    "# from dataprep import transform_indices, leave_last_out, verify_time_split, reindex_data, generate_interactions_matrix\n",
    "# from evaluation import topn_recommendations, model_evaluate, downvote_seen_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From dataprep file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_last_out(data, userid='userid', timeid='timestamp'):\n",
    "    data_sorted = data.sort_values(by=timeid)\n",
    "    holdout = data_sorted.drop_duplicates(\n",
    "        subset=[userid], keep='last'\n",
    "    ) # split the last item from each user's history\n",
    "    remaining = data.drop(holdout.index) # store the remaining data - will be our training\n",
    "    return remaining, holdout\n",
    "\n",
    "\n",
    "def to_numeric_id(data, field):\n",
    "    idx_data = data[field].astype(\"category\")\n",
    "    idx = idx_data.cat.codes\n",
    "    idx_map = idx_data.cat.categories.rename(field)\n",
    "    return idx, idx_map\n",
    "\n",
    "\n",
    "def transform_indices(data: pd.DataFrame, users: str, items:str, inplace: bool=False):\n",
    "    data_index = {}\n",
    "    data_codes = {}\n",
    "    for entity, field in zip(['users', 'items'], [users, items]):\n",
    "        new_index, data_index[entity] = to_numeric_id(data, field)\n",
    "        if inplace:\n",
    "            data.loc[:, field] = new_index\n",
    "        else:\n",
    "            data_codes[field] = new_index\n",
    "\n",
    "    if data_codes:\n",
    "        data = data.assign(**data_codes) # makes a copy of data\n",
    "    return data, data_index\n",
    "\n",
    "\n",
    "def reindex_data(\n",
    "        data: pd.DataFrame,\n",
    "        data_index: dict,\n",
    "        entities: Optional[Union[str, list[str]]] = None,\n",
    "        filter_invalid: bool = True,\n",
    "        inplace: bool = False\n",
    "    ):\n",
    "    if entities is None:\n",
    "        entities = data_index.keys()\n",
    "    if isinstance(entities, str): # handle single entity provided as a string\n",
    "        entities = [entities]\n",
    "    data_codes = {}\n",
    "    for entity in entities:\n",
    "        entity_index = data_index[entity]\n",
    "        field = entity_index.name # extract the field name\n",
    "        new_index = entity_index.get_indexer(data[field])\n",
    "        if inplace:\n",
    "            data.loc[:, field] = new_index # assign new values inplace\n",
    "        else:\n",
    "            data_codes[field] = new_index # store new values\n",
    "    if data_codes:\n",
    "        data = data.assign(**data_codes) # assign new values by making a copy\n",
    "    if filter_invalid: # discard unrecognized entity index\n",
    "        valid_values = [f'{data_index[entity].name}>=0' for entity in entities]\n",
    "        data = data.query(' and '.join(valid_values))\n",
    "    return data\n",
    "\n",
    "\n",
    "def generate_interactions_matrix(data, data_description, rebase_users=False):\n",
    "    n_users = data_description['n_users']\n",
    "    n_items = data_description['n_items']\n",
    "    # get indices of observed data\n",
    "    user_idx = data[data_description['users']].values\n",
    "    if rebase_users: # handle non-contiguous index of test users\n",
    "        # This ensures that all user ids are contiguous and start from 0,\n",
    "        # which helps ensure data consistency at the scoring stage.\n",
    "        user_idx, user_index = pd.factorize(user_idx, sort=True)\n",
    "        n_users = len(user_index)\n",
    "    item_idx = data[data_description['items']].values\n",
    "    feedback = data[data_description['feedback']].values\n",
    "    # construct rating matrix\n",
    "    return csr_matrix((feedback, (user_idx, item_idx)), shape=(n_users, n_items))\n",
    "\n",
    "\n",
    "def verify_time_split(before, after, target_field='userid', timeid='timestamp'):\n",
    "    before_ts = before.groupby(target_field)[timeid].max()\n",
    "    after_ts = after.groupby(target_field)[timeid].min()\n",
    "    assert (\n",
    "        before_ts\n",
    "        .reindex(after_ts.index)\n",
    "        .combine(after_ts, lambda x, y: True if x!=x else x <= y)\n",
    "    ).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From evaluation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downvote_seen_items(scores, data, data_description):\n",
    "    assert isinstance(scores, np.ndarray), 'Scores must be a dense numpy array!'\n",
    "    itemid = data_description['items']\n",
    "    userid = data_description['users']\n",
    "    # get indices of observed data, corresponding to scores array\n",
    "    # we need to provide correct mapping of rows in scores array into\n",
    "    # the corresponding user index (which is assumed to be sorted)\n",
    "    row_idx, test_users = pd.factorize(data[userid], sort=True)\n",
    "    assert len(test_users) == scores.shape[0]\n",
    "    col_idx = data[itemid].values\n",
    "    # downvote scores at the corresponding positions\n",
    "    scores[row_idx, col_idx] = scores.min() - 1\n",
    "\n",
    "\n",
    "def topn_recommendations(scores, topn=10):\n",
    "    recommendations = np.apply_along_axis(topidx, 1, scores, topn)\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def topidx(a, topn):\n",
    "    parted = np.argpartition(a, -topn)[-topn:]\n",
    "    return parted[np.argsort(-a[parted])]\n",
    "\n",
    "\n",
    "def model_evaluate(recommended_items, holdout, holdout_description, topn=10):\n",
    "    itemid = holdout_description['items']\n",
    "    holdout_items = holdout[itemid].values\n",
    "    assert recommended_items.shape[0] == len(holdout_items)\n",
    "    hits_mask = recommended_items[:, :topn] == holdout_items.reshape(-1, 1)\n",
    "    # HR calculation\n",
    "    hr = np.mean(hits_mask.any(axis=1))\n",
    "    # MRR calculation\n",
    "    n_test_users = recommended_items.shape[0]\n",
    "    hit_rank = np.where(hits_mask)[1] + 1.0\n",
    "    mrr = np.sum(1 / hit_rank) / n_test_users\n",
    "    # coverage calculation\n",
    "    n_items = holdout_description['n_items']\n",
    "    cov = np.unique(recommended_items).size / n_items\n",
    "    return {\n",
    "        f'hr@{topn}' : hr,\n",
    "        f'mrr@{topn}' : mrr,\n",
    "        f'cov@{topn}' : cov,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clicks_train = pd.read_parquet(\"./data/otto_exploded_dataset/clicks/train\")\n",
    "df_carts_train = pd.read_parquet(\"./data/otto_exploded_dataset/carts/train\")\n",
    "df_orders_train = pd.read_parquet(\"./data/otto_exploded_dataset/orders/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: none\">\n",
       "    <tr style=\"border: none\"><td style=\"border: none\"> <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>1521766</td>\n",
       "      <td>1659729979807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>1725503</td>\n",
       "      <td>1659774028031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>528847</td>\n",
       "      <td>1659774232119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>1816325</td>\n",
       "      <td>1659774337835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0</td>\n",
       "      <td>984597</td>\n",
       "      <td>1659774357892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div> </td>\n",
       "<td style=\"border: none\"> <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1</td>\n",
       "      <td>854637</td>\n",
       "      <td>1659990941327</td>\n",
       "      <td>carts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1</td>\n",
       "      <td>215311</td>\n",
       "      <td>1659990964841</td>\n",
       "      <td>carts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1</td>\n",
       "      <td>711125</td>\n",
       "      <td>1659991053886</td>\n",
       "      <td>carts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>105393</td>\n",
       "      <td>1659991168139</td>\n",
       "      <td>carts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>3</td>\n",
       "      <td>984459</td>\n",
       "      <td>1659818148834</td>\n",
       "      <td>carts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div> </td>\n",
       "<td style=\"border: none\"> <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>3</td>\n",
       "      <td>1018433</td>\n",
       "      <td>1659999789346</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>3</td>\n",
       "      <td>54857</td>\n",
       "      <td>1659999789346</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>11</td>\n",
       "      <td>1145803</td>\n",
       "      <td>1659902394985</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>35</td>\n",
       "      <td>1162085</td>\n",
       "      <td>1659788011065</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>40</td>\n",
       "      <td>223422</td>\n",
       "      <td>1660302982234</td>\n",
       "      <td>orders</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div> </td>\n",
       "    </tr>\n",
       "    </table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clicks_train = pd.read_parquet(\"./data/otto_exploded_dataset/clicks/train\")\n",
    "df_carts_train = pd.read_parquet(\"./data/otto_exploded_dataset/carts/train\")\n",
    "df_orders_train = pd.read_parquet(\"./data/otto_exploded_dataset/orders/train\")\n",
    "\n",
    "df_clicks_train['type'] = 1\n",
    "\n",
    "print_frames([\n",
    "    df_clicks_train.head(),\n",
    "    df_carts_train.head(),\n",
    "    df_orders_train.head()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_, holdout_ = leave_last_out(df_clicks_train, userid='session', timeid='ts')\n",
    "verify_time_split(training_, holdout_, target_field='session', timeid='ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, data_index = transform_indices(training_, 'session', 'aid')\n",
    "holdout = (\n",
    "    reindex_data(holdout_, data_index, filter_invalid=True)\n",
    "    .sort_values('session')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aid'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_index['users']), len(data_index['items'])\n",
    "data_index['users'].name\n",
    "data_index['items'].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    feedback = 'type',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PureSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svd_model(config, data, data_description):\n",
    "    source_matrix = generate_interactions_matrix(data, data_description, rebase_users=False)\n",
    "    _, s, vt = svds(\n",
    "        source_matrix.astype('f8'),\n",
    "        k=config['rank'],\n",
    "        return_singular_vectors='vh'\n",
    "    )\n",
    "    sidx = np.argsort(-s)\n",
    "    singular_values = s[sidx]\n",
    "    item_factors = np.ascontiguousarray(vt[sidx, :].T)\n",
    "    return item_factors, singular_values\n",
    "\n",
    "def svd_model_scoring(params, data, data_description):\n",
    "    item_factors, sigma = params\n",
    "    test_matrix = generate_interactions_matrix(data, data_description, rebase_users=True)\n",
    "    scores = test_matrix.dot(item_factors) @ item_factors.T\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_config = {'rank': 200}\n",
    "\n",
    "V, sigma = svd_params = build_svd_model(svd_config, training, data_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<304164x680757 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3220087 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix = generate_interactions_matrix(training, data_description, rebase_users=True)\n",
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "V_sparse = sparse.csr_matrix(V)\n",
    "VT_sparse = sparse.csr_matrix(V.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<680757x200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 136151400 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200x680757 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 136151400 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304164, 680757)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test_matrix * V_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<304164x200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 60832800 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can't compute this multiplication in reasonable time\n",
    "b = a * VT_sparse\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last multiplication requires $O(60832800*136151400*680757)=O(10^21)$ elementary operations that will take approximately 10^13 seconds or 316 887 years on this laptop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
